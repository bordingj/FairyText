{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    two young  white males are outside near many b...\n",
       "1    several men in hard hats are operating a giant...\n",
       "2     a little girl climbing into a wooden playhouse  \n",
       "3    a man in a blue shirt is standing on a ladder ...\n",
       "4            two men are at the stove preparing food  \n",
       "dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile('[^a-z +]')\n",
    "with open('data/multi30k/train.en','r') as f:\n",
    "    sentences = pd.Series([pattern.sub(' ',x.lower()) for x in f.readlines()])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_set = set([])\n",
    "for sent in sentences:\n",
    "    word_set |= set([x.strip() for x in sent.split(' ')])\n",
    "all_words = sorted(list(word_set))\n",
    "id2word_dict = dict(zip(range(len(all_words)),all_words))\n",
    "id2word_dict[len(all_words)] = 'Ø'\n",
    "word2id_dict = {word: id for id, word in id2word_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_IDs(sentence):\n",
    "    IDs = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            IDs.append( word2id_dict[word] )\n",
    "        except:\n",
    "            IDs.append( word2id_dict['Ø'] )\n",
    "    return np.asarray(IDs, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [9027, 9666, 0, 9481, 5028, 319, 5775, 5503, 5...\n",
       "1    [7384, 5190, 4245, 3896, 3916, 319, 5701, 1, 3...\n",
       "2     [1, 4870, 3585, 1657, 4360, 1, 9570, 6253, 0, 0]\n",
       "3    [1, 5032, 4245, 1, 878, 7473, 4387, 8090, 5677...\n",
       "4    [9027, 5190, 319, 407, 8640, 8202, 6431, 3341,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentences_as_ints = pd.Series([get_word_IDs(sent) for sent in sentences])\n",
    "Sentences_as_ints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rush import vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_length_int_vecs = vecs.IntVecs(Sentences_as_ints.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 9027  4870  4561  ...   9688  9688  9688\n",
      " 9027  3588  4077  ...   9688  9688  9688\n",
      "    1  4870   373  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  5032  9547  ...   9688  9688  9688\n",
      "    1  4026  4461  ...   9688  9688  9688\n",
      " 9027  9561    68  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 128x31]\n",
      "\n",
      "\n",
      " 8650  4387     1  ...   9688  9688  9688\n",
      "    1  9560  6938  ...   9688  9688  9688\n",
      " 9027  4267   319  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  4870   984  ...   9688  9688  9688\n",
      "    1  3527  5651  ...   9688  9688  9688\n",
      "    1  9560  4245  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 128x25]\n",
      "\n",
      "\n",
      " 8814  8502     1  ...   9688  9688  9688\n",
      "  218  5669  2017  ...   9688  9688  9688\n",
      "    1  4870   984  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  5032  4387  ...   9688  9688  9688\n",
      " 8650  4387     1  ...   9688  9688  9688\n",
      " 9327   355   222  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 128x27]\n",
      "\n",
      "\n",
      " 9445  3585  4245  ...   9688  9688  9688\n",
      "    1  5032   222  ...   9688  9688  9688\n",
      "    1  3585  8090  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 9027  9561  8090  ...   9688  9688  9688\n",
      " 9027  5190  7608  ...   9688  9688  9688\n",
      " 9666   984  9547  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 128x36]\n",
      "\n",
      "\n",
      "    1  1078  2510  ...   9688  9688  9688\n",
      "    1  7638  4387  ...   9688  9688  9688\n",
      "    1  9560  9405  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "  218   109  9560  ...   9688  9688  9688\n",
      " 9027  6062  6254  ...   9688  9688  9688\n",
      "    1  1687  9547  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 128x26]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minibatchsize = 128\n",
    "for i in range(5):\n",
    "    minibatch = variable_length_int_vecs.make_padded_minibatch(\n",
    "        np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), \n",
    "        fill_value = word2id_dict['Ø']\n",
    "    )\n",
    "    print(minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.5 µs ± 119 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit variable_length_int_vecs.make_padded_minibatch( np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), fill_value = word2id_dict['Ø'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
