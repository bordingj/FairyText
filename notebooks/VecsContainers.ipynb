{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jonatan/Dropbox\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecs Containers\n",
    "\n",
    "When training NLP models you normally have input samples which are of variable length. For example sentences with different number of words. But in order to train with minibatches you need to stack them in a matrix. \n",
    "I have implemented different containers for extremely fast minibatch-creation from variable length vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rush.vecs import FloatVecs, IntVecs, ShortVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create instances of these containers from a list of 1d numpy.ndarrays or torch-tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Load some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    two young  white males are outside near many b...\n",
       "1    several men in hard hats are operating a giant...\n",
       "2     a little girl climbing into a wooden playhouse  \n",
       "3    a man in a blue shirt is standing on a ladder ...\n",
       "4            two men are at the stove preparing food  \n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pattern = re.compile('[^a-z +]')\n",
    "with open('data/multi30k/train.en','r') as f:\n",
    "    sentences = pd.Series([pattern.sub(' ',x.lower()) for x in f.readlines()])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build mappings to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_set = set([])\n",
    "for sent in sentences:\n",
    "    word_set |= set([x.strip() for x in sent.split(' ')])\n",
    "all_words = sorted(list(word_set))\n",
    "id2word_dict = dict(zip(range(len(all_words)),all_words))\n",
    "id2word_dict[len(all_words)] = 'Ø'\n",
    "word2id_dict = {word: id for id, word in id2word_dict.items()}\n",
    "\n",
    "def get_word_IDs(sentence):\n",
    "    IDs = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            IDs.append( word2id_dict[word] )\n",
    "        except:\n",
    "            IDs.append( word2id_dict['Ø'] )\n",
    "    return np.asarray(IDs, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sentences as variable length vectors of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [9027, 9666, 0, 9481, 5028, 319, 5775, 5503, 5...\n",
       "1    [7384, 5190, 4245, 3896, 3916, 319, 5701, 1, 3...\n",
       "2     [1, 4870, 3585, 1657, 4360, 1, 9570, 6253, 0, 0]\n",
       "3    [1, 5032, 4245, 1, 878, 7473, 4387, 8090, 5677...\n",
       "4    [9027, 5190, 319, 407, 8640, 8202, 6431, 3341,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentences_as_ints = pd.Series([get_word_IDs(sent) for sent in sentences])\n",
    "Sentences_as_ints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make an instance of a IntVecs container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_length_int_vecs = IntVecs(Sentences_as_ints.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_padded_minibatch method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to make 5 different random minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    1  9560  4245  ...   9688  9688  9688\n",
      " 5032  9322  4870  ...   9688  9688  9688\n",
      " 6694  6062   407  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  9560  4245  ...   9688  9688  9688\n",
      "  218  5669  9560  ...   9688  9688  9688\n",
      " 8680  6062   319  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x30]\n",
      "\n",
      "\n",
      " 9027  6774   986  ...   9688  9688  9688\n",
      "    1  3804  4387  ...   9688  9688  9688\n",
      " 8604  6249   319  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  1143  5651  ...   9688  9688  9688\n",
      "    1  1544  4387  ...   9688  9688  9688\n",
      "    1  5032  6447  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x29]\n",
      "\n",
      "\n",
      " 4394  8952  2628  ...   9688  9688  9688\n",
      "    1  5032  9547  ...   9688  9688  9688\n",
      "    1  5032  7533  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 9027  9666  9561  ...   9688  9688  9688\n",
      "    1  4870  3585  ...   9688  9688  9688\n",
      " 5680  5032  4387  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x29]\n",
      "\n",
      "\n",
      "    1  6771  3821  ...   9688  9688  9688\n",
      " 3799   222  3585  ...   9688  9688  9688\n",
      " 8665  3585  4387  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "  218  5715  7474  ...   9688  9688  9688\n",
      "    1  3763  5651  ...   9688  9688  9688\n",
      " 9027  6062  9547  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x30]\n",
      "\n",
      "\n",
      " 7865  6062   319  ...   9688  9688  9688\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      "    1  9560  4245  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1   984  2954  ...   9688  9688  9688\n",
      "    1  2230  9405  ...   9688  9688  9688\n",
      "    1  6149  5651  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x27]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minibatchsize = 256\n",
    "for i in range(5):\n",
    "    minibatch = variable_length_int_vecs.make_padded_minibatch(\n",
    "        np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), # randon indices\n",
    "        fill_value = word2id_dict['Ø'] # padding value\n",
    "    )\n",
    "    print(minibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive implementation would look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def naive_implementation(variable_length_vecs, indices, fill_value):\n",
    "    max_len = max([len(x) for x in variable_length_vecs.iloc[indices]])\n",
    "    out = np.empty( (len(indices),max_len), dtype=np.int32)\n",
    "    out.fill(fill_value)\n",
    "    for i, vec in enumerate(variable_length_vecs.iloc[indices]):\n",
    "        out[i,:len(vec)] = vec\n",
    "    return torch.from_numpy(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to time the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 µs ± 16 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit naive_implementation(Sentences_as_ints, np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), fill_value = word2id_dict['Ø'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.9 µs ± 23.2 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit variable_length_int_vecs.make_padded_minibatch( np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), fill_value = word2id_dict['Ø'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_minibatch_with_random_lengths method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets say you have huge documents instead of short sentences. Then you might want to randomly sample into each document with a fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    1  5447  7377  ...   3786  4833  4327\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  2510  4387  ...   9688  9688  9688\n",
      "    1  9560  3841  ...   9688  9688  9688\n",
      "  218  5669   373  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      " 5677  8224  2916  ...   7318  2626  1213\n",
      " 1547  6254  9547  ...   9688  9688  9688\n",
      " 9027  3348  6249  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  2126  5651  ...   9688  9688  9688\n",
      "    1  2510  4387  ...   9688  9688  9688\n",
      "    1  1544  9405  ...      0  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "    1  6092  4245  ...   9688  9688  9688\n",
      "    1  9560  9324  ...   9688  9688  9688\n",
      "  984  4245  5715  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  5032  4387  ...   9688  9688  9688\n",
      "    1  3434  6119  ...   7749     0     0\n",
      " 5061  6062   319  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "    1   823   222  ...   9688  9688  9688\n",
      "    1  5032  6254  ...   9688  9688  9688\n",
      "    1  5721  6079  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 8640  1078  2510  ...   9688  9688  9688\n",
      "  218    90  5032  ...   9688  9688  9688\n",
      "  700  2230  4245  ...    136     0     0\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "  984  2508  3806  ...   8640  5980  5651\n",
      " 4006  4387     1  ...   8555     0     0\n",
      "    1  5032  9322  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 8563   319  6254  ...   4037     0     0\n",
      "    1  7737  1392  ...   9688  9688  9688\n",
      "    1  9560  6257  ...      0     0     0\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_len = 20\n",
    "out_buffer = np.empty( (minibatchsize,max_len), dtype=np.int32 )\n",
    "for i in range(5):\n",
    "    minibatch = variable_length_int_vecs.make_minibatch_with_random_lengths(\n",
    "        np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), \n",
    "        fill_value = word2id_dict['Ø'],\n",
    "        out=out_buffer,\n",
    "        max_len=max_len)\n",
    "    print(minibatch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
