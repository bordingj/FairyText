{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jonatan/Dropbox/FairyText\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecs Containers\n",
    "\n",
    "When training NLP models you normally have input samples which are of variable length. For example sentences with different number of words. But in order to train with minibatches you need to stack them in a matrix. \n",
    "I have implemented different containers for extremely fast minibatch-creation from variable length vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rush.vecs import FloatVecs, IntVecs, ShortVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create instances of these containers from a list of 1d numpy.ndarrays or torch-tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Load some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    two young  white males are outside near many b...\n",
       "1    several men in hard hats are operating a giant...\n",
       "2     a little girl climbing into a wooden playhouse  \n",
       "3    a man in a blue shirt is standing on a ladder ...\n",
       "4            two men are at the stove preparing food  \n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pattern = re.compile('[^a-z +]')\n",
    "with open('data/multi30k/train.en','r') as f:\n",
    "    sentences = pd.Series([pattern.sub(' ',x.lower()) for x in f.readlines()])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build mappings to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_set = set([])\n",
    "for sent in sentences:\n",
    "    word_set |= set([x.strip() for x in sent.split(' ')])\n",
    "all_words = sorted(list(word_set))\n",
    "id2word_dict = dict(zip(range(len(all_words)),all_words))\n",
    "id2word_dict[len(all_words)] = 'Ø'\n",
    "word2id_dict = {word: id for id, word in id2word_dict.items()}\n",
    "\n",
    "def get_word_IDs(sentence):\n",
    "    IDs = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            IDs.append( word2id_dict[word] )\n",
    "        except:\n",
    "            IDs.append( word2id_dict['Ø'] )\n",
    "    return np.asarray(IDs, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sentences as variable length vectors of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [9027, 9666, 0, 9481, 5028, 319, 5775, 5503, 5...\n",
       "1    [7384, 5190, 4245, 3896, 3916, 319, 5701, 1, 3...\n",
       "2     [1, 4870, 3585, 1657, 4360, 1, 9570, 6253, 0, 0]\n",
       "3    [1, 5032, 4245, 1, 878, 7473, 4387, 8090, 5677...\n",
       "4    [9027, 5190, 319, 407, 8640, 8202, 6431, 3341,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentences_as_ints = pd.Series([get_word_IDs(sent) for sent in sentences])\n",
    "Sentences_as_ints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make an instance of a IntVecs container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_length_int_vecs = IntVecs(Sentences_as_ints.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_padded_minibatch method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to make 5 different random minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    1  5032   222  ...   9688  9688  9688\n",
      " 8640  2502  9134  ...   9688  9688  9688\n",
      "    1  5032  1928  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "  218   373  9560  ...   9688  9688  9688\n",
      "    1  5032  9405  ...   9688  9688  9688\n",
      " 9027  6062  8088  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x28]\n",
      "\n",
      "\n",
      "    1  3763  5651  ...   9688  9688  9688\n",
      " 6062  2233   407  ...   9688  9688  9688\n",
      " 6062  3562  5677  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "  218   373  5032  ...   9688  9688  9688\n",
      " 8650   319  4178  ...   9688  9688  9688\n",
      "    1  3763  5651  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x40]\n",
      "\n",
      "\n",
      "    1  2510  4387  ...   9688  9688  9688\n",
      " 8650   319  9027  ...   9688  9688  9688\n",
      "    1  4703  5032  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  9560  9547  ...   9688  9688  9688\n",
      " 9027  5190   222  ...   9688  9688  9688\n",
      "    1  8420  2638  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x31]\n",
      "\n",
      "\n",
      "    1  9666  5032  ...   9688  9688  9688\n",
      "    1  3585  3637  ...   9688  9688  9688\n",
      "    1  4870  3585  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 9027  5190   407  ...   9688  9688  9688\n",
      "    1  5372  7954  ...   9688  9688  9688\n",
      "    1  4870   823  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x29]\n",
      "\n",
      "\n",
      "    1  9276  9187  ...   9688  9688  9688\n",
      "    1  3763  5651  ...   9688  9688  9688\n",
      "    1  9584  4387  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  1544  7082  ...   9688  9688  9688\n",
      "    1  9560  9405  ...   9688  9688  9688\n",
      " 6062   407     1  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x34]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minibatchsize = 256\n",
    "for i in range(5):\n",
    "    minibatch = variable_length_int_vecs.make_padded_minibatch(\n",
    "        np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), # randon indices\n",
    "        fill_value = word2id_dict['Ø'] # padding value\n",
    "    )\n",
    "    print(minibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive implementation would look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def naive_implementation(variable_length_vecs, indices, fill_value):\n",
    "    max_len = max([len(x) for x in variable_length_vecs.iloc[indices]])\n",
    "    out = np.empty( (len(indices),max_len), dtype=np.int32)\n",
    "    out.fill(fill_value)\n",
    "    for i, vec in enumerate(variable_length_vecs.iloc[indices]):\n",
    "        out[i,:len(vec)] = vec\n",
    "    return torch.from_numpy(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to time the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352 µs ± 18.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit naive_implementation(Sentences_as_ints, np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), fill_value = word2id_dict['Ø'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.5 µs ± 792 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit variable_length_int_vecs.make_padded_minibatch( np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), fill_value = word2id_dict['Ø'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_minibatch_with_random_lengths method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets say you have huge documents instead of short sentences. Then you might want to randomly sample into each document with a fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 4689  5190   319  ...   3897     0     0\n",
      " 9481  5032  4077  ...   9688  9688  9688\n",
      " 8640   493  5651  ...   3845     0     0\n",
      "       ...          ⋱          ...       \n",
      " 8680  9666  3588  ...   9688  9688  9688\n",
      "    1  9560  7497  ...   9688  9688  9688\n",
      " 7865  6062  6894  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "    1  3894  9666  ...      1  7559     0\n",
      "    1  5032  4387  ...   9688  9688  9688\n",
      "    1   544     0  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  3763  5651  ...   9688  9688  9688\n",
      "    1  3763  5651  ...   1608     0     0\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "    1  5032  4245  ...   8192     0     0\n",
      " 9560  4245  9481  ...   6211   222  3808\n",
      " 1898  9585  4245  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 8640  3038   319  ...   9688  9688  9688\n",
      " 9027  5190  8090  ...   9688  9688  9688\n",
      "  109  5032  4077  ...   9515     0     0\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      " 8640  4653  4077  ...   9688  9688  9688\n",
      "    1  2510  9324  ...   9688  9688  9688\n",
      "    1  9560  1360  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1   984  9405  ...   9688  9688  9688\n",
      "    1  9666  4653  ...      0  9688  9688\n",
      "    1  9666   984  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "  218  4262  9561  ...      0     0  9688\n",
      "    1  4870   984  ...      0     0  9688\n",
      " 8640  7749  9560  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  9193     0  ...   4049  9346     0\n",
      "    1  5032  9405  ...   9688  9688  9688\n",
      " 2231  6074  5677  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_len = 20\n",
    "out_buffer = np.empty( (minibatchsize,max_len), dtype=np.int32 )\n",
    "for i in range(5):\n",
    "    minibatch = variable_length_int_vecs.make_minibatch_with_random_lengths(\n",
    "        np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), \n",
    "        fill_value = word2id_dict['Ø'],\n",
    "        out=out_buffer,\n",
    "        max_len=max_len)\n",
    "    print(minibatch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
