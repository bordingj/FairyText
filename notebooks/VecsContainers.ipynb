{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jonatan/Dropbox/FairyText\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecs Containers\n",
    "\n",
    "When training NLP models you normally have input samples which are of variable length. For example sentences with different number of words. But in order to train with minibatches you need to stack them in a matrix. \n",
    "I have implemented different containers for extremely fast minibatch-creation from variable length vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rush.vecs import FloatVecs, IntVecs, ShortVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create instances of these containers from a list of 1d numpy.ndarrays or torch-tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Load some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    two young  white males are outside near many b...\n",
       "1    several men in hard hats are operating a giant...\n",
       "2     a little girl climbing into a wooden playhouse  \n",
       "3    a man in a blue shirt is standing on a ladder ...\n",
       "4            two men are at the stove preparing food  \n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pattern = re.compile('[^a-z +]')\n",
    "with open('data/multi30k/train.en','r') as f:\n",
    "    sentences = pd.Series([pattern.sub(' ',x.lower()) for x in f.readlines()])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build vocabulary and mappings to and from integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'a',\n",
       " 'aaa',\n",
       " 'aaron',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abdomen',\n",
       " 'aberdeen',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'abs',\n",
       " 'abstract',\n",
       " 'accelerates',\n",
       " 'accept',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accident',\n",
       " 'accommodates',\n",
       " 'accompanied']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set = set([])\n",
    "for sent in sentences:\n",
    "    word_set |= set([x.strip() for x in sent.split(' ')])\n",
    "all_words = sorted(list(word_set))\n",
    "all_words[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word_dict = dict(zip(range(len(all_words)),all_words))\n",
    "id2word_dict[len(all_words)] = 'Ø'\n",
    "word2id_dict = {word: id for id, word in id2word_dict.items()}\n",
    "\n",
    "def get_word_IDs(sentence):\n",
    "    IDs = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            IDs.append( word2id_dict[word] )\n",
    "        except:\n",
    "            IDs.append( word2id_dict['Ø'] )\n",
    "    return np.asarray(IDs, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sentences as variable length vectors of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [9027, 9666, 0, 9481, 5028, 319, 5775, 5503, 5...\n",
       "1    [7384, 5190, 4245, 3896, 3916, 319, 5701, 1, 3...\n",
       "2     [1, 4870, 3585, 1657, 4360, 1, 9570, 6253, 0, 0]\n",
       "3    [1, 5032, 4245, 1, 878, 7473, 4387, 8090, 5677...\n",
       "4    [9027, 5190, 319, 407, 8640, 8202, 6431, 3341,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentences_as_ints = pd.Series([get_word_IDs(sent) for sent in sentences])\n",
    "Sentences_as_ints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make an instance of a IntVecs container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_length_int_vecs = IntVecs(Sentences_as_ints.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_padded_minibatch method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to make 5 different random minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 6062  4245     1  ...   9688  9688  9688\n",
      " 9027  3588  4245  ...   9688  9688  9688\n",
      "    1  2510  8920  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  7749  5032  ...   9688  9688  9688\n",
      " 3405  6257     1  ...   9688  9688  9688\n",
      "    1  8224  9193  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x32]\n",
      "\n",
      "\n",
      "    1  2510  4495  ...   9688  9688  9688\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      " 5032  9547     1  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 9027  1547  1652  ...   9688  9688  9688\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      "    1  5032  9547  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x33]\n",
      "\n",
      "\n",
      " 7616  9201  1764  ...   9688  9688  9688\n",
      "    1  3894  8604  ...   9688  9688  9688\n",
      "    1  5032  8501  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      "    1  5032   222  ...   9688  9688  9688\n",
      " 8680  6062  6985  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x35]\n",
      "\n",
      "\n",
      " 2502  9405  6529  ...   9688  9688  9688\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      " 9027  2512  9547  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 9027  9666  3588  ...   9688  9688  9688\n",
      "    1  5032  4387  ...   9688  9688  9688\n",
      " 9027  5190   319  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x33]\n",
      "\n",
      "\n",
      " 5032  9547  6587  ...   9688  9688  9688\n",
      "    1  9666  9560  ...   9688  9688  9688\n",
      " 9027  5190     0  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 9027  2245  7652  ...   9688  9688  9688\n",
      "    1  2537  6564  ...   9688  9688  9688\n",
      "    1  5032     0  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x36]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minibatchsize = 256\n",
    "for i in range(5):\n",
    "    minibatch = variable_length_int_vecs.make_padded_minibatch(\n",
    "        np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), # randon indices\n",
    "        fill_value = word2id_dict['Ø'] # padding value\n",
    "    )\n",
    "    print(minibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive implementation would look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def naive_implementation(variable_length_vecs, indices, fill_value):\n",
    "    max_len = max([len(x) for x in variable_length_vecs.iloc[indices]])\n",
    "    out = np.empty( (len(indices),max_len), dtype=np.int32)\n",
    "    out.fill(fill_value)\n",
    "    for i, vec in enumerate(variable_length_vecs.iloc[indices]):\n",
    "        out[i,:len(vec)] = vec\n",
    "    return torch.from_numpy(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to time the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 µs ± 21.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit naive_implementation(Sentences_as_ints, np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), fill_value = word2id_dict['Ø'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.3 µs ± 3.73 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit variable_length_int_vecs.make_padded_minibatch( np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), fill_value = word2id_dict['Ø'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_minibatch_with_random_lengths method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets say you have huge documents instead of short sentences. Then you might want to randomly sample into each document with a fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    1  1757  6257  ...   9688  9688  9688\n",
      "    1  4892   360  ...   9688  9688  9688\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 6062  8090   407  ...   9688  9688  9688\n",
      " 9560  5677  8640  ...   9688  9688  9688\n",
      " 3403  7628   319  ...      0  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "    1   626  6248  ...   9688  9688  9688\n",
      "    1  3763  5651  ...   9688  9688  9688\n",
      "    1  4689  2126  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  5668  5032  ...   9688  9688  9688\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      " 5032  4245  3913  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "    1  9666  3585  ...   9688  9688  9688\n",
      "    1  9481  5027  ...      0  9688  9688\n",
      "    0     0  6062  ...   6254     1  3500\n",
      "       ...          ⋱          ...       \n",
      "    1  9666   984  ...   9688  9688  9688\n",
      " 7616  6062  4029  ...   9688  9688  9688\n",
      " 4050  6062  7613  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "    1  2510  4495  ...   9688  9688  9688\n",
      "  984  6938     1  ...   8640  7559     0\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  5032  9145  ...      0     0  9688\n",
      "    1  6092  4387  ...   9688  9688  9688\n",
      "    1  3585  4387  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      " 8640  8343  1389  ...      0  9688  9688\n",
      "    1  7737  1544  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 4561  6638   338  ...   9688  9688  9688\n",
      "    1  3763  5651  ...   9688  9688  9688\n",
      "    1  9560  2587  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_len = 20\n",
    "out_buffer = np.empty( (minibatchsize,max_len), dtype=np.int32 )\n",
    "for i in range(5):\n",
    "    minibatch = variable_length_int_vecs.make_minibatch_with_random_lengths(\n",
    "        np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), \n",
    "        fill_value = word2id_dict['Ø'],\n",
    "        out=out_buffer,\n",
    "        max_len=max_len)\n",
    "    print(minibatch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
