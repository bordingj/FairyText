{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jonatan/Dropbox/FairyText\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecs Containers\n",
    "\n",
    "When training NLP models you normally have input samples which are of variable length. For example sentences with different number of words. But in order to train with minibatches you need to stack them in a matrix. \n",
    "I have implemented different containers for extremely fast minibatch-creation from variable length vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rush.vecs import FloatVecs, IntVecs, ShortVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create instances of these containers from a list of 1d numpy.ndarrays or torch-tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Load some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    two young  white males are outside near many b...\n",
       "1    several men in hard hats are operating a giant...\n",
       "2     a little girl climbing into a wooden playhouse  \n",
       "3    a man in a blue shirt is standing on a ladder ...\n",
       "4            two men are at the stove preparing food  \n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pattern = re.compile('[^a-z +]')\n",
    "with open('data/multi30k/train.en','r') as f:\n",
    "    sentences = pd.Series([pattern.sub(' ',x.lower()) for x in f.readlines()])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build vocabulary and mappings to and from integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'a',\n",
       " 'aaa',\n",
       " 'aaron',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abdomen',\n",
       " 'aberdeen',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'abs',\n",
       " 'abstract',\n",
       " 'accelerates',\n",
       " 'accept',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accident',\n",
       " 'accommodates',\n",
       " 'accompanied']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set = set([])\n",
    "for sent in sentences:\n",
    "    word_set |= set([x.strip() for x in sent.split(' ')])\n",
    "all_words = sorted(list(word_set))\n",
    "all_words[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word_dict = dict(zip(range(len(all_words)),all_words))\n",
    "id2word_dict[len(all_words)] = 'Ø'\n",
    "word2id_dict = {word: id for id, word in id2word_dict.items()}\n",
    "\n",
    "def get_word_IDs(sentence):\n",
    "    IDs = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            IDs.append( word2id_dict[word] )\n",
    "        except:\n",
    "            IDs.append( word2id_dict['Ø'] )\n",
    "    return np.asarray(IDs, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sentences as variable length vectors of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [9027, 9666, 0, 9481, 5028, 319, 5775, 5503, 5...\n",
       "1    [7384, 5190, 4245, 3896, 3916, 319, 5701, 1, 3...\n",
       "2     [1, 4870, 3585, 1657, 4360, 1, 9570, 6253, 0, 0]\n",
       "3    [1, 5032, 4245, 1, 878, 7473, 4387, 8090, 5677...\n",
       "4    [9027, 5190, 319, 407, 8640, 8202, 6431, 3341,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentences_as_ints = pd.Series([get_word_IDs(sent) for sent in sentences])\n",
    "Sentences_as_ints.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make an instance of a IntVecs container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_length_int_vecs = IntVecs(Sentences_as_ints.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_padded_minibatch method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to make 5 different random minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    1  7180  6248  ...   9688  9688  9688\n",
      "    1  2510  7082  ...   9688  9688  9688\n",
      " 8680  8581  9094  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "  218   373  9560  ...   9688  9688  9688\n",
      "  218  5669  2017  ...   9688  9688  9688\n",
      " 9027  5190     0  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x30]\n",
      "\n",
      "\n",
      "    1  5032  4245  ...   9688  9688  9688\n",
      "    1  5032  9405  ...   9688  9688  9688\n",
      " 9027  3800  5677  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 9027  9561  9322  ...   9688  9688  9688\n",
      "    1  4026  4387  ...   9688  9688  9688\n",
      "    1  7638  8451  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x28]\n",
      "\n",
      "\n",
      "    1   772  4245  ...   9688  9688  9688\n",
      " 9027  9561  4706  ...   9688  9688  9688\n",
      "    1  9666  9560  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 8680  6062  7608  ...   9688  9688  9688\n",
      "    1  1078  2510  ...   9688  9688  9688\n",
      " 8680  1898  9585  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x29]\n",
      "\n",
      "\n",
      "    1  7737   373  ...   9688  9688  9688\n",
      "    1   823  2510  ...   9688  9688  9688\n",
      " 6092  4245  5715  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  9560  9547  ...   9688  9688  9688\n",
      "    1  5032   222  ...   9688  9688  9688\n",
      "    1  5032  6412  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x29]\n",
      "\n",
      "\n",
      " 8680  6062  4029  ...   9688  9688  9688\n",
      "  218  5668  5032  ...   9688  9688  9688\n",
      "    1  5032  4387  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      "    1  3015  4245  ...   9688  9688  9688\n",
      "    1  5669  5032  ...   9688  9688  9688\n",
      "    1  3763  5651  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x27]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minibatchsize = 256\n",
    "for i in range(5):\n",
    "    minibatch = variable_length_int_vecs.make_padded_minibatch(\n",
    "        np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), # randon indices\n",
    "        fill_value = word2id_dict['Ø'] # padding value\n",
    "    )\n",
    "    print(minibatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive implementation would look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def naive_implementation(variable_length_vecs, indices, fill_value):\n",
    "    max_len = max([len(x) for x in variable_length_vecs.iloc[indices]])\n",
    "    out = np.empty( (len(indices),max_len), dtype=np.int32)\n",
    "    out.fill(fill_value)\n",
    "    for i, vec in enumerate(variable_length_vecs.iloc[indices]):\n",
    "        out[i,:len(vec)] = vec\n",
    "    return torch.from_numpy(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to time the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 µs ± 26.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit naive_implementation(Sentences_as_ints, np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), fill_value = word2id_dict['Ø'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.5 µs ± 1.49 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit variable_length_int_vecs.make_padded_minibatch( np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), fill_value = word2id_dict['Ø'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_minibatch_with_random_lengths method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets say you have huge documents instead of short sentences. Then you might want to randomly sample into each document with a fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 9688  9688  9688  ...   2145  5782     1\n",
      " 9688  9688  9688  ...   6936     1   768\n",
      " 9688  9688     1  ...   4387  7613  5677\n",
      "       ...          ⋱          ...       \n",
      " 9688  9688  9688  ...      1  7829  3500\n",
      " 9688  9688  9688  ...   9688  9688     1\n",
      " 9688  9688  9688  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      " 9688  9688  9688  ...      1  5032   222\n",
      " 9688  9027  3588  ...   9688  9688  9688\n",
      " 1450     0     0  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 9688  9688  9688  ...   5715   556  4245\n",
      " 8640  7789     0  ...   9688  9688  9688\n",
      " 9688  9688  9688  ...   4037     0     0\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      " 7198  4387  1360  ...   9688  9688  9688\n",
      " 9688  9688  9688  ...   4585     0     0\n",
      " 9688  9688  9688  ...      0     0  9688\n",
      "       ...          ⋱          ...       \n",
      "  407  5214  5620  ...   9688  9688  9688\n",
      " 9688  9688  9688  ...   9688  9688  9688\n",
      "    1   878  4407  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      " 9688  9688  9688  ...      1  1939     0\n",
      "    0  9688  9688  ...   9688  9688  9688\n",
      " 9688  9688  9688  ...   2112  4774     0\n",
      "       ...          ⋱          ...       \n",
      " 6728     1   924  ...   9688  9688  9688\n",
      " 9688  9688  9688  ...   9688  9688  9688\n",
      " 9688  9688  9688  ...      0  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n",
      "\n",
      " 9688  9688  9688  ...   3034  4994  5651\n",
      "  836  9472     1  ...   9688  9688  9688\n",
      " 9688  9688  9688  ...   9688  9688  9688\n",
      "       ...          ⋱          ...       \n",
      " 7552     0     0  ...   9688  9688  9688\n",
      " 9688  9688  9688  ...    567  6411  4245\n",
      " 9688  9688  9688  ...   9688  9688  9688\n",
      "[torch.IntTensor of size 256x20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_len = 20\n",
    "out_buffer = np.empty( (minibatchsize,max_len), dtype=np.int32 )\n",
    "for i in range(5):\n",
    "    minibatch = variable_length_int_vecs.make_minibatch_with_random_lengths(\n",
    "        np.random.randint(0,variable_length_int_vecs.num_vecs, minibatchsize), \n",
    "        fill_value = word2id_dict['Ø'],\n",
    "        out=out_buffer,\n",
    "        max_len=max_len)\n",
    "    print(minibatch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
